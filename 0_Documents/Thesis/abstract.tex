\newpage
{\Huge \bf Abstract}
\vspace{24pt} 

%One of the goals of Natural Language Understanding \textit{NLU} is to formalize written text in a way, such that linguistic features can be captured through computational models, which can then again be used for downstream machine learning tasks.
%The most popular methodology in NLU is the use of vectors that represent written text, including word-vectors, sentence-vectors, etc. 
%These vectors are often referred to as \textit{embedding} vectors, as they embed more complex concepts into a vector representation.

Word and contextual word embeddings can be considered as the fundamental unit of machine learning in the domain of natural language.
For a variety of downstream tasks, any shortcomings in the embeddings will propagate on to the performance of the target task.
Given that language representation models such as BERT only capture a black-box function $f$ between input and output, our aim is to understand how the subspace organization of context embeddings relates to linguistic features.
We focus our analysis on \textit{semantics}, which captures the meaning within language, as this is one of the most important features of language. 
We analyse the BERT language model, as it provides a good balance between popularity, close to state-of-the-art performance, and generalizability to other modern language models due to it being a model based on the transformer architecture.
\\

Our main contributions are the following: (1) We test for linear separability and ability to partition the space into semantic clusters within the sampled BERT vectors.
On one side, we show that while linear separability is possible. 
On the other side, it seems nearly impossible to cleanly cluster the set of contextual word embeddings produced by BERT into different semantic classes as defined by WordNet.
We conclude that BERT organizes the embedding vectors very little by semantics alone.
More generally, any linguistic features that is implied by context is included as well
This can easily introduce undesirable properties such as strong sentiment, leading to considerable bias in downstream tasks.
(2) We analyze the relationship between part-of-speech and semantics. 
We show that these show a strong correlation in languages and that modern language models capture this strong correlation.
This affects the conclusion of some related work which had analysed language models that capture semantics, but which did not account for the correlation between part-of-speech and semantics.
(3) Finally, we introduce additional parameters for words whose sampled embedding vectors have high variance over the embedding space.
We investigate what downstream tasks are most affected  and use this as a proxy to understand what information is captured the most by the directions with high variance. \\

\newpage
\vspace*{\fill}
