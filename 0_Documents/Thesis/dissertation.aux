\relax 
\providecommand \oddpage@label [2]{}
\citation{dropping_perf1}
\citation{dropping_perf2}
\citation{density_matching}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Scope of Work}{1}\protected@file@percent }
\citation{gaussian_embedding}
\citation{density_matching}
\citation{density_matching}
\citation{density_matching}
\citation{flowpp}
\citation{neuralsplineflow}
\citation{variational_inference_using_normalized_flows}
\citation{nvp}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Gaussian Embeddings}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Word representations via Gaussian Embeddings}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Symmetric similarity: expected likelihood or probability product kernel}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Asymmetric divergence: KL-Divergence}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Uncertainty calculation:}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}General random information}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Normalising Flows}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Planar Flow}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Real NVP (2017)}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Inverse AR Flow (2017)}{17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Non-Linear Independent Components Estimation (NICE)}{17}\protected@file@percent }
\citation{variational_inference_using_normalized_flows}
\citation{normalising_flows}
\citation{normalising_flows}
\citation{iaf}
\citation{nvp}
\citation{variational_inference_using_normalized_flows}
\citation{glow}
\@writefile{toc}{\contentsline {subsubsection}{Glow: Generative Flows with Invertible 1x1 Convolutions (2018)}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Flow++ (2019)}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{21}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {paragraph}{online data}{21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{offline data}{21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Methods using GANs (and other stuff..)}{22}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Methods using Normalising Flows}{22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Density Matching for Bilingual Word Embeddings (Zhou 2019)}{22}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Methods viewing this problem as an Optimal Transport (OT) Problem}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Gromov-Wasserstein Alignment of Word Embedding Spaces}{26}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces How to write algorithms}}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Supervised Case: Procrustes}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Unsupervised Maps: Optimal Transport}{27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Graph translation using normalizing flows}{29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Using monolingual word-embeddings to map one to another}{29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Cross-lingual word-mappings (Artetxe 2018)}{29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Bilingual Lexicon Induction through Unsupervised Machine Translation (Artetxe 2019)}{30}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Analysis of the current state of the art}{31}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Our Method}{33}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Further Work}{35}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Evaluation}{37}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{39}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
