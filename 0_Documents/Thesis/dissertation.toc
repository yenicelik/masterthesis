\contentsline {chapter}{\numberline {1}Introduction}{1}% 
\contentsline {chapter}{\numberline {2}Motivation}{3}% 
\contentsline {chapter}{\numberline {3}Background}{5}% 
\contentsline {section}{\numberline {3.1}Word Embeddings}{5}% 
\contentsline {paragraph}{Word-Embeddings}{5}% 
\contentsline {paragraph}{Distance}{6}% 
\contentsline {paragraph}{Learning a distance}{7}% 
\contentsline {paragraph}{Going from the distributional structure of sentences to learning distances between words.}{7}% 
\contentsline {paragraph}{However, we do not need to only look at only the previous words}{8}% 
\contentsline {subsection}{\numberline {3.1.1}Static Word Embeddings}{10}% 
\contentsline {subsubsection}{Basic Model}{10}% 
\contentsline {subsubsection}{Word2Vec}{11}% 
\contentsline {subsubsection}{GloVe}{12}% 
\contentsline {subsubsection}{Gaussian Embeddings}{13}% 
\contentsline {paragraph}{Symmetric similarity: expected likelihood or probability product kernel}{14}% 
\contentsline {paragraph}{Asymmetric divergence: KL-Divergence}{14}% 
\contentsline {paragraph}{Uncertainty calculation:}{15}% 
\contentsline {subsection}{\numberline {3.1.2}Context Embeddings}{16}% 
\contentsline {subsubsection}{The Transformer Architecture}{16}% 
\contentsline {subsubsection}{ELMo}{16}% 
\contentsline {subsubsection}{BERT}{16}% 
\contentsline {subsubsection}{GPT and GPT-2}{16}% 
\contentsline {subsection}{\numberline {3.1.3}Other methods}{16}% 
\contentsline {subsubsection}{Generating "static" word-embeddings through contextual embeddings}{16}% 
\contentsline {section}{\numberline {3.2}Resources and Datasets}{19}% 
\contentsline {subsubsection}{WordNet}{19}% 
\contentsline {subsubsection}{SemCor dataset}{19}% 
\contentsline {subsubsection}{News dataset}{19}% 
\contentsline {subsubsection}{GLUE benchmark dataset}{19}% 
\contentsline {chapter}{\numberline {4}Related Work}{21}% 
\contentsline {section}{\numberline {4.1}Structure inside BERT}{21}% 
\contentsline {section}{\numberline {4.2}Metric Learning and Disentanglement}{23}% 
\contentsline {section}{\numberline {4.3}Zero shot and One shot learning }{23}% 
\contentsline {section}{\numberline {4.4}Clustering Algorithms}{23}% 
\contentsline {section}{\numberline {4.5}Applications of word vector}{23}% 
\contentsline {subsubsection}{Word2Vec}{24}% 
\contentsline {chapter}{\numberline {5}Analysis of the current state of the art}{27}% 
\contentsline {section}{\numberline {5.1}On the Linear Separability of meaning within sampled BERT vectors}{27}% 
\contentsline {subsection}{\numberline {5.1.1}Motivation}{27}% 
\contentsline {subsection}{\numberline {5.1.2}Experiment setup}{28}% 
\contentsline {subsection}{\numberline {5.1.3}Results}{29}% 
\contentsline {section}{\numberline {5.2}On the Clusterability of meaning within sampled BERT vectors}{29}% 
\contentsline {subsection}{\numberline {5.2.1}Motivation}{29}% 
\contentsline {subsection}{\numberline {5.2.2}Experiment setup}{29}% 
\contentsline {subsection}{\numberline {5.2.3}Results}{29}% 
\contentsline {section}{\numberline {5.3}Correlation between Part of Speech and Context within BERT}{29}% 
\contentsline {subsection}{\numberline {5.3.1}Motivation}{29}% 
\contentsline {subsection}{\numberline {5.3.2}Experiment setup}{29}% 
\contentsline {subsection}{\numberline {5.3.3}Results}{29}% 
\contentsline {chapter}{\numberline {6}Our Method}{31}% 
\contentsline {subsection}{\numberline {6.0.1}BERnie PoS}{31}% 
\contentsline {subsubsection}{Motivation}{31}% 
\contentsline {subsubsection}{Experiment setup}{31}% 
\contentsline {subsection}{\numberline {6.0.2}BERnie Meaning}{31}% 
\contentsline {subsubsection}{Motivation}{31}% 
\contentsline {subsubsection}{Experiment setup}{31}% 
\contentsline {subsection}{\numberline {6.0.3}BERnie Meaning with additional pre-training}{31}% 
\contentsline {subsubsection}{Motivation}{31}% 
\contentsline {subsubsection}{Experiment setup}{31}% 
\contentsline {subsection}{\numberline {6.0.4}Compressing the non-lexical out}{31}% 
\contentsline {subsubsection}{Motivation}{31}% 
\contentsline {subsubsection}{Experiment setup}{31}% 
\contentsline {chapter}{\numberline {7}Further Work}{33}% 
\contentsline {chapter}{\numberline {8}Evaluation}{35}% 
\contentsline {chapter}{\numberline {9}Conclusion}{37}% 
